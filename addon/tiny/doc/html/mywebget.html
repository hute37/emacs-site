<HTML>
<HEAD>
<TITLE>mywebget.pl - Perl Web URL fetch program</TITLE>
<LINK REV="made" HREF="mailto:gp@familiehaase.de">
</HEAD>

<BODY>

<A NAME="__index__"></A>
<!-- INDEX BEGIN -->

<UL>

	<LI><A HREF="#name">NAME</A></LI>
	<LI><A HREF="#synopsis">SYNOPSIS</A></LI>
	<LI><A HREF="#options">OPTIONS</A></LI>
	<UL>

		<LI><A HREF="#general options">General options</A></LI>
		<LI><A HREF="#miscellaneous options">Miscellaneous options</A></LI>
	</UL>

	<LI><A HREF="#readme">README</A></LI>
	<UL>

		<LI><A HREF="#wget and this program">Wget and this program</A></LI>
		<LI><A HREF="#short introduction">Short introduction</A></LI>
	</UL>

	<LI><A HREF="#examples">EXAMPLES</A></LI>
	<UL>

		<LI><A HREF="#list of directives in configuration file">List of directives in configuration file</A></LI>
	</UL>

	<LI><A HREF="#errors">ERRORS</A></LI>
	<LI><A HREF="#environment">ENVIRONMENT</A></LI>
	<LI><A HREF="#see also">SEE ALSO</A></LI>
	<LI><A HREF="#availability">AVAILABILITY</A></LI>
	<LI><A HREF="#script categories">SCRIPT CATEGORIES</A></LI>
	<LI><A HREF="#prerequisites">PREREQUISITES</A></LI>
	<LI><A HREF="#corequisites">COREQUISITES</A></LI>
	<LI><A HREF="#osnames">OSNAMES</A></LI>
	<LI><A HREF="#version">VERSION</A></LI>
	<LI><A HREF="#author">AUTHOR</A></LI>
</UL>
<!-- INDEX END -->

<HR>
<P>
<HR>
<H1><A NAME="name">NAME</A></H1>
<P>mywebget.pl - Perl Web URL fetch program</P>
<P>
<HR>
<H1><A NAME="synopsis">SYNOPSIS</A></H1>
<PRE>
    mywebget.pl <A HREF="http://example.com/">http://example.com/</A> [URL ...]
    mywebget.pl --config $HOME/config/mywebget.conf --Tag linux --Tag emacs ..
    mywebget.pl --verbose --overwrite <A HREF="http://example.com/">http://example.com/</A>
    mywebget.pl --verbose --overwrite --Output ~/dir/ <A HREF="http://example.com/">http://example.com/</A>
    mywebget.pl --new --overwrite <A HREF="http://example.com/kit-1.1.tar.gz">http://example.com/kit-1.1.tar.gz</A></PRE>
<P>
<HR>
<H1><A NAME="options">OPTIONS</A></H1>
<P>
<H2><A NAME="general options">General options</A></H2>
<DL>
<DT><STRONG><A NAME="item_%2D%2DCreate%2Dpaths"><STRONG>--Create-paths</STRONG></A></STRONG><BR>
<DD>
Create paths that do not exist in <CODE>lcd:</CODE> directives.
<P>By default, any LCD directive to non-existing directory will interrupt
program. With this option, local directories are created as needed making
it possible to re-create the exact structure as it is in configuration
file.</P>
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dconfig_FILE"><STRONG>--config FILE</STRONG></A></STRONG><BR>
<DD>
This option can be given multiple times. All configurations are read.
<P>Read URLs from configuration file. If no configuration file is given, file
pointed by enviromnet variable is read. See ENVIRONMENT.</P>
<P><CODE>Comments</CODE></P>
<P>The configuration file is NOT Perl code. Comments start with hash character
#.</P>
<P><CODE>Variables</CODE></P>
<P>At this point, variable expansions happen only in <STRONG>lcd:</STRONG>. Do not try
to use them anywhere else, like in URLs.</P>
<P>Path variables for <STRONG>lcd:</STRONG> are defined using following notation, spaces are
not allowed in VALUE part (no directory names with spaces). Varaible names
are case sensitive. Variables substitute environment varaibales with the
same name. Environment variables are immediately available.</P>
<PRE>
    VARIABLE = /home/my/dir         # define variable
    VARIABLE = $dir/some/file       # Use previously defined variable
    FTP      = $HOME/ftp            # Use environment variable</PRE>
<P>The right hand can refer to previously defined variables or existing
environment variables. Repeat, this is not Perl code although it may
look like one, but just an allowed syntax in the configuration file. Notice
that there is dollar to the right hand&gt; when variable is referred, but no
dollar to the left hand side when variable is defined. Here is example
of a possible configuration file contant. The tags are hierarchically
ordered without a limit.</P>
<P>Warning: remember to use different variables names in separate
include files. All variables are global.</P>
<P><CODE>Includes</CODE></P>
<P>It is possible to include more configuration files with statement</P>
<PRE>
    INCLUDE &lt;path-to-file-name&gt;</PRE>
<P>Variable expansions are possible in the file name. There is no limit how
many or how deep include structure is used. Every file is included only
once, so it is safe to to have multiple includes to the same file.
Every include is read, so put the most importat override includes last:</P>
<PRE>
    INCLUDE &lt;etc/mywebget.conf&gt;             # Global
    INCLUDE &lt;$HOME/config/mywebget.conf&gt;    # HOME overrides it</PRE>
<P>A special <CODE>THIS</CODE> tag means relative path of the current include file,
which makes it possible to include several files form the same
directory where a initial include file resides</P>
<PRE>
    # Start of config at /etc/mywebget.conf</PRE>
<PRE>
    # THIS = /etc, current file's location
    include &lt;THIS/mywebget-others.conf&gt;</PRE>
<PRE>
    # Refers to directory where current user is: the pwd
    include &lt;mywebget-others.conf&gt;&gt;</PRE>
<PRE>
    # end</PRE>
<P><CODE>Configuraton file example</CODE></P>
<PRE>
    #   $HOME/config/mywebget.conf - Perl mywebget.pl configuration file</PRE>
<PRE>
    ROOT   = $HOME                      # define variables
    CONF   = $HOME/config
    UPDATE = $ROOT/updates
    DOWNL  = $ROOT/download</PRE>
<PRE>
    #   Include more configuration files. It is possible to
    #   split a huge file in pieces and have &quot;linux&quot;,
    #   &quot;win32&quot;, &quot;debian&quot;, &quot;emacs&quot; configurations in separate
    #   and manageable files.</PRE>
<PRE>
    INCLUDE &lt;$CONF/mywebget-other.conf&gt;
    INCLUDE &lt;$CONF/mywebget-more.conf&gt;</PRE>
<PRE>
    tag1: local-copies tag1: local      # multiple names to this category</PRE>
<PRE>
        lcd:  $UPDATE                   # chdir directive</PRE>
<PRE>
        <A HREF="file://absolute/dir/file-1.23.tar.gz">file://absolute/dir/file-1.23.tar.gz</A></PRE>
<PRE>
    tag1: external</PRE>
<PRE>
      lcd:  $DOWNL</PRE>
<PRE>
      tag2: external-http</PRE>
<PRE>
        <A HREF="http://www.example.com/page.html">http://www.example.com/page.html</A>
        <A HREF="http://www.example.com/page.html">http://www.example.com/page.html</A> save:/dir/dir/page.html</PRE>
<PRE>
      tag2: external-ftp</PRE>
<PRE>
        <A HREF="ftp://ftp.com/dir/file.txt.gz">ftp://ftp.com/dir/file.txt.gz</A> save:xx-file.txt.gz login:foo pass:passwd x:</PRE>
<PRE>
        lcd: $HOME/download-kit</PRE>
<PRE>
        <A HREF="ftp://ftp.com/dir/kit-1.1.tar.gz">ftp://ftp.com/dir/kit-1.1.tar.gz</A> new:</PRE>
<PRE>
      tag2: package-x</PRE>
<PRE>
        lcd: $DOWNL/package-x</PRE>
<PRE>
        #  Person announces new files in his homepage, download all
        #  announced files. Unpack everything (x:) and remove any
        #  existing directories (xopt:rm)</PRE>
<PRE>
        <A HREF="http://some.com/~foo">http://some.com/~foo</A>   page:find  pregexp:\.tar\.gz$ x: xopt:rm</PRE>
<PRE>
    # End of configuration file mywebget.conf</PRE>
<DT><STRONG><A NAME="item_%2D%2Dextract"><STRONG>--extract</STRONG></A></STRONG><BR>
<DD>
Unpack any files after retrieving them. The command to unpack typical
archive files are defined in a program. Make sure these programs are
along path. Win32 users are encouraged to install the Cygwin utilities
where these programs come standard. Refer to section SEE ALSO.
<PRE>
  .tar =&gt; tar
  .tgz =&gt; tar + gzip
  .gz  =&gt; gzip
  .bz2 =&gt; bzip2
  .zip =&gt; unzip</PRE>
<P></P>
<DT><STRONG><A NAME="item_%2D%2DFirewall_FIREWALL"><STRONG>--Firewall FIREWALL</STRONG></A></STRONG><BR>
<DD>
Use FIREWALL when accessing files via ftp:// protocol.
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dnew_%2Dn"><STRONG>--new -n</STRONG></A></STRONG><BR>
<DD>
Get newest file. This applies to datafiles, which do not have extension
.asp or .html. When new releases are announced, the version
number in filename usually tells which is the current one so getting
harcoded file with:
<PRE>
    mywebget.pl -o -v <A HREF="http://example.com/dir/program-1.3.tar.gz">http://example.com/dir/program-1.3.tar.gz</A></PRE>
<P>is not usually practical from automation point of view. Adding <STRONG>--new</STRONG>
option to the command line causes double pass: a) the whole
<A HREF="http://example.com/dir/">http://example.com/dir/</A> is examined for all files. b) files matching
approximately filename program-1.3.tar.gz are examined, heuristically
sorted and file with latest version number is retrieved.</P>
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dno%2Dlcd"><STRONG>--no-lcd</STRONG></A></STRONG><BR>
<DD>
Ignore <CODE>lcd:</CODE> directives in configuration file.
<P>In the configuration file, any <CODE>lcd:</CODE> directives are obeyed as they are seen.
But if you do want to retrieve URL to your current directory, be sure to
supply this option. Otherwise the file will end to the directory pointer by
<CODE>lcd:</CODE>.</P>
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dno%2Dsave"><STRONG>--no-save</STRONG></A></STRONG><BR>
<DD>
Ignore <CODE>save:</CODE> directives in configuration file. If the URLs have
<CODE>save:</CODE> options, they are ignored during fetch. You usually want to
combine <STRONG>--no-lcd</STRONG> with <STRONG>--no-save</STRONG>
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dno%2Dextract"><STRONG>--no-extract</STRONG></A></STRONG><BR>
<DD>
Ignore <A HREF="#item_x%3A"><CODE>x:</CODE></A> directives in configuration file.
<P></P>
<DT><STRONG><A NAME="item_%2D%2DOutput_DIR"><STRONG>--Output DIR</STRONG></A></STRONG><BR>
<DD>
Before retrieving any files, chdir to DIR.
<P></P>
<DT><STRONG><A NAME="item_%2D%2Doverwrite"><STRONG>--overwrite</STRONG></A></STRONG><BR>
<DD>
Allow overwriting existing files when retrieving URLs.
Combine this with <STRONG>--skip-version</STRONG> if you periodically update files.
<P></P>
<DT><STRONG><A NAME="item_%2D%2DProxy_PROXY"><STRONG>--Proxy PROXY</STRONG></A></STRONG><BR>
<DD>
Use PROXY server for HTTP. (See <STRONG>--Firewall</STRONG> for FTP.). The port number is
optional in the call:
<PRE>
    --Proxy this.proxy.com:8080
    --Proxy <A HREF="http://this.proxy.com:8080/">http://this.proxy.com:8080/</A>
    --Proxy this.proxy.com
    --Proxy <A HREF="http://this.proxy.com/">http://this.proxy.com/</A></PRE>
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dprefix_PREFIX"><STRONG>--prefix PREFIX</STRONG></A></STRONG><BR>
<DD>
Add PREFIX to all retrieved files.
<P></P>
<DT><STRONG><A NAME="item_%2D%2DPostfix_POSTFIX"><STRONG>--Postfix POSTFIX </STRONG></A></STRONG><BR>
<DD>
Add POSTFIX to all retrieved files.
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dprefix%2Ddate_%2DD"><STRONG>--prefix-date -D</STRONG></A></STRONG><BR>
<DD>
Add iso8601 ``:YYYY-MM-DD'' prefix to all retrived files.
This is added before possible <STRONG>--prefix-www</STRONG> or <STRONG>--prefix</STRONG>.
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dprefix%2Dwww_%2DW"><STRONG>--prefix-www -W</STRONG></A></STRONG><BR>
<DD>
Usually the files are stored with the same name as in the URL dir, but
if you retrieve files that have identical names you can store each
page separately so that the file name is prefixed by the site name.
<PRE>
    <A HREF="http://example.com/page.html">http://example.com/page.html</A>    --&gt; example.com::page.html
    <A HREF="http://example2.com/page.html">http://example2.com/page.html</A>   --&gt; example2.com::page.html</PRE>
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dregexp_REGEXP"><STRONG>--regexp REGEXP</STRONG></A></STRONG><BR>
<DD>
Retrieve URLs matching REGEXP from your <CODE>configuration</CODE> file. This cancels
<STRONG>--Tag</STRONG> options in the command line.
<P></P>
<DT><STRONG><A NAME="item_%2D%2DRegexp_REGEXP"><STRONG>--Regexp REGEXP</STRONG></A></STRONG><BR>
<DD>
Retrieve file matching at the destination URL site. This is like ``Connect
to the URL and get all files matching REGEXP''. Here all gzip compressed
files are found form an HTTP server's directory listing
<PRE>
    mywebget.pl -v -R &quot;\.gz&quot; <A HREF="http://example.com/archive/">http://example.com/archive/</A></PRE>
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dstdout"><STRONG>--stdout</STRONG></A></STRONG><BR>
<DD>
Retrieve URL and write it to stdout.
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dskip%2Dversion"><STRONG>--skip-version</STRONG></A></STRONG><BR>
<DD>
Do not download files that have version number and which already exists on
disk. Suppose you have these files and you use option <STRONG>--skip-version</STRONG>:
<PRE>
    kit.tar.gz
    file-1.1.tar.gz</PRE>
<P>Only file.txt is retrieved, because file-1.1.tar.gz contains version number
and the file has not changed since last retrieval. The idea is, that in
every release the number in in distribution increases, but there may be
distributions which do not contain version number. In regular intervals
you may want to load those kits again, but skip versioned files. In short:
This option does not make much sense without additional option <STRONG>--new</STRONG></P>
<P>If you want to reload versioned file again, add option <STRONG>--overwrite</STRONG>.</P>
<P></P>
<DT><STRONG><A NAME="item_%2D%2DTag_NAME_%5BNAME%5D_%2E%2E%2E"><STRONG>--Tag NAME [NAME] ...</STRONG></A></STRONG><BR>
<DD>
Search tag NAME from the config file and download only entries defined
under that tag. Refer to <STRONG>--config FILE</STRONG> option description. You can give
Multiple <STRONG>--Tag</STRONG> switches. Combining this option with <STRONG>--regexp</STRONG>
does not make sense and the concequencies are undefined.
<P></P></DL>
<P>
<H2><A NAME="miscellaneous options">Miscellaneous options</A></H2>
<DL>
<DT><STRONG><A NAME="item_%2D%2Ddebug_LEVEL_%2Dd_LEVEL"><STRONG>--debug LEVEL -d LEVEL</STRONG></A></STRONG><BR>
<DD>
Turn on debug with positive LEVEL number. Zero means no debug.
This option turns on <STRONG>--verbose</STRONG> too.
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dhelp_%2Dh"><STRONG>--help -h</STRONG></A></STRONG><BR>
<DD>
Print help page in text.
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dhelp%2Dhtml"><STRONG>--help-html</STRONG></A></STRONG><BR>
<DD>
Print help page in HTML.
<P>Print help page.</P>
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dselftest"><STRONG>--selftest</STRONG></A></STRONG><BR>
<DD>
Run some internal tests. For maintainer or developer only.
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dtest_%2Dt"><STRONG>--test -t</STRONG></A></STRONG><BR>
<DD>
Run in test mode.
<P></P>
<DT><STRONG><A NAME="item_%2D%2Dverbose_%2Dv_%5BNUMBER%5D"><STRONG>--verbose -v [NUMBER]</STRONG></A></STRONG><BR>
<DD>
Print verbose messages.
<P></P>
<DT><STRONG><A NAME="item_%2D%2DVersion_%2DV"><STRONG>--Version -V</STRONG></A></STRONG><BR>
<DD>
Print program's version information.
<P></P></DL>
<P>
<HR>
<H1><A NAME="readme">README</A></H1>
<P>Automate periodic downloads of released files and packages.</P>
<P>
<H2><A NAME="wget and this program">Wget and this program</A></H2>
<P>At this point you may wonder, where would you need this perl program when
<CODE>wget(1)</CODE> C-program has been the standard for ages. Well, 1) Perl is cross
platform and more easily extendable 2) You can put file download criterias
to configuration file and use perl regular epxressions 3) the program can
anlyze web-pages and ``search'' for the download link as you instruct 4) it
contains heuristics to track more newer version of the file.</P>
<P>But it does not replace <CODE>webget(1)</CODE> because this program does not offer
as many options as web get, not even recursive downloads. The best advice
is to dedicate this program to ``batch'' download the files that you monitor
most of the time and use <CODE>wget(1)</CODE> for everything else.</P>
<P>
<H2><A NAME="short introduction">Short introduction</A></H2>
<P>This small utility makes it possible to keep a list of URLs in a
configuration file and periodically retrieve those pages or files with
simple commands. This utility is best suited for small batch jobs to
download e.g. most recent versions of software files. If you use an URL
that is already on disk, be sure to supply option <STRONG>--overwrite</STRONG> to allow
overwriting existing files.</P>
<P>While you can run this program from command line to retrieve individual
files, program has been designed to use separate configuration file via
<STRONG>--config</STRONG> option. In the configuration file you can control the
downloading with separate directives like <CODE>save:</CODE> which tells to save the
file under different name.</P>
<P>The simplest way to retreive the latest version of a kit from FTP site is:</P>
<PRE>
    mywebget.pl --new --overwite --verbose \
       <A HREF="http://www.example.com/kit-1.00.tar.gz">http://www.example.com/kit-1.00.tar.gz</A></PRE>
<P>Don't worry about the filename ``kit-1.00.tar.gz''. The latest version, say,
kit-3.08.tar.gz will be retrieved. The option <STRONG>--new</STRONG> instructs to find
newer version than the provided URL.</P>
<P>If the URL ends to slash, then directory list at the remote machine
is stored to file:</P>
<PRE>
    !path!000root-file</PRE>
<P>The content of this file can be either index.html or the directory listing
depending on the used http or ftp protocol.</P>
<P>
<HR>
<H1><A NAME="examples">EXAMPLES</A></H1>
<P>Get <CODE>file(s)</CODE> from site:</P>
<PRE>
    mywebget.pl <A HREF="http://www.example.com/dir/package.tar.gz">http://www.example.com/dir/package.tar.gz</A> ..</PRE>
<P>Get all mailing list archive files that match ``gz'':</P>
<PRE>
    mywebget.pl -R gz  <A HREF="http://somewhere.at/mailing-list/archive/download/">http://somewhere.at/mailing-list/archive/download/</A></PRE>
<P>Read a directory and store it to filename YYYY-MM-DD::!dir!000root-file.</P>
<PRE>
    mywebget.pl --prefix-date --overwrite --verbose <A HREF="http://www.example.com/dir/">http://www.example.com/dir/</A></PRE>
<P>To update newest version of the kit, but only if there is none in the
disk already. The --new option instructs to find nwer packages and
the filename is used only for guidance how the file looks like:</P>
<PRE>
    mywebget.pl --overwrite --skip-version --new --verbose \
        <A HREF="ftp://ftp.example.com/dir/packet-1.23.tar.gz">ftp://ftp.example.com/dir/packet-1.23.tar.gz</A></PRE>
<P>To overwrite file and add a date prefix to the file name:</P>
<PRE>
    mywebget.pl --prefix-date --overwrite --verbose \
       <A HREF="http://www.example.com/file.pl">http://www.example.com/file.pl</A></PRE>
<PRE>
    --&gt; YYYY-MM-DD::file.pl</PRE>
<P>To add date and WWW site prefix to the filenames:</P>
<PRE>
    mywebget.pl --prefix-date --prefix-www --overwrite --verbose \
       <A HREF="http://www.example.com/file.pl">http://www.example.com/file.pl</A></PRE>
<PRE>
    --&gt; YYYY-MM-DD::www.example.com::file.pl</PRE>
<P>Get all updated files under KITS and use default configuration file:</P>
<PRE>
    mywebget.pl --verbose --overwrite --skip-version --new --Tag kits
    mywebget.pl -v -o -s -n -T kits</PRE>
<P>Get files as they read in the configuration file to the current directory,
ignoring any <CODE>lcd:</CODE> and <CODE>save:</CODE> directives:</P>
<PRE>
    mywebget.pl --config $HOME/config/mywebget.conf /
        --no-lcd --no-save --overwrite --verbose \
        <A HREF="http://www.example.com/file.pl">http://www.example.com/file.pl</A></PRE>
<P>To check if <CODE>lcd:</CODE> directives refer to live directories on disk, run the
program with non-matching regexp and it parses the file and checks the
lcds along the way:</P>
<PRE>
    mywebget.pl -v -r dummy-regexp</PRE>
<PRE>
    --&gt;</PRE>
<PRE>
    mywebget.pl.DirectiveLcd: LCD [$EUSR/directory ...]
    is not a directory at /users/foo/bin/mywebget.pl line 889.</PRE>
<P>
<H2><A NAME="list of directives in configuration file">List of directives in configuration file</A></H2>
<P>All the directives must in the same line where the URL is. The programs
scans lines and determines all options given in line for the URL.
Directives can be overriden by command line options.</P>
<DL>
<DT><STRONG><A NAME="item_cnv%3ACONVERSION"><STRONG>cnv:CONVERSION</STRONG></A></STRONG><BR>
<DD>
Currently only <STRONG>cnv:text</STRONG> is available.
<P>Convert downloaded page to text. This option always needs either
<STRONG>save:</STRONG> or <STRONG>rename:</STRONG>, because only those change the filename. Here is an
example:</P>
<PRE>
    <A HREF="http://example.com/dir/file.html">http://example.com/dir/file.html</A> cnv:text save:file.txt
    <A HREF="http://example.com/dir/">http://example.com/dir/</A> page:find pregexp:\.html cnv:text rename:s/html/txt/</PRE>
<P>A <STRONG>text:</STRONG> shorthand directive can be used instead of <STRONG>cnv:text</STRONG>.</P>
<P></P>
<DT><STRONG><A NAME="item_lcd%3ADIRECTORY"><STRONG>lcd:DIRECTORY</STRONG></A></STRONG><BR>
<DD>
Set local download directory to DIRECTORY (chdir to it). Any environment
variables are substituted in path name. If this tag is found, it replaces
setting of <STRONG>--Output</STRONG>. If path is not a directory, terminate with error.
See also <STRONG>--Create-paths</STRONG> and <STRONG>--no-lcd</STRONG>.
<P></P>
<DT><STRONG><A NAME="item_login%3ALOGIN%2DNAME"><STRONG>login:LOGIN-NAME</STRONG></A></STRONG><BR>
<DD>
Ftp login name. Default value is ``anonymous''.
<P></P>
<DT><STRONG><A NAME="item_new%3A"><STRONG>new:</STRONG></A></STRONG><BR>
<DD>
Get newest file. This variable is reset to the value of <STRONG>--new</STRONG> after the
line has been processed. Newest means, that an <CODE>ls()</CODE> command is run in the
ftp, and something equivalent in HTTP ``ftp directories'', and any files that
resemble the filename is examined, sorted and heurestically determined
according to version number of file which one is the latest. For example
files that have version information in YYYYMMDD format will most likely to
be retrieved right.
<P>Time stamps of the files are not checked.</P>
<P>The only requirement is that filename <CODE>must</CODE> follow the universal version
numbering standard for released kits:</P>
<PRE>
    FILE-VERSION.extension      # de facto VERSION is defined as [\d.]+</PRE>
<PRE>
    file-19990101.tar.gz        # ok
    file-1999.0101.tar.gz       # ok
    file-1.2.3.5.tar.gz         # ok</PRE>
<PRE>
    file1234.txt                # not recognized. Must have &quot;-&quot;
    file-0.23d.tar.gz           # warning ! No letters allowed 0.23d</PRE>
<P>Files that have some alphabetic version indicator at the end of VERSION
are not handled correctly. Bitch the developer and persuade him to stick
to the de facto standard so that files can be retrieved intelligently.</P>
<P></P>
<DT><STRONG><A NAME="item_overwrite%3A_o%3A"><STRONG>overwrite:</STRONG> <STRONG>o:</STRONG></A></STRONG><BR>
<DD>
Same as turning on <STRONG>--overwrite</STRONG>
<P></P>
<DT><STRONG><A NAME="item_page%3A"><STRONG>page:</STRONG></A></STRONG><BR>
<DD>
Download the HTTP page or apply command to it. A simple example, the
contact page name ``index.html'', ``welcome.html'' etc. is not known:
<PRE>
   <A HREF="http://some.com/~foo">http://some.com/~foo</A> page: save:foo-homepage.html</PRE>
<P><CODE>More about</CODE> <STRONG>page:</STRONG> <CODE>directive and downloading difficult packages</CODE></P>
<P><STRONG>REMEMBER: All the regular epxression used in the configuration file have
a limitation of keeping together. This means that there must be no space
characters in the regular expressions, because it will terminate reading
the item.</STRONG> Like if you write pregexp:(this regexp ) =&gt; it must be written
pregexp:(this\s+regexp\s)</P>
<P>Read the HTTP url page ``as is'' and parse page content. You need this
directive if the archive is not stored in HTTP server directory (similar
to ftp dir), but the maintainer has set up a separate HTML page where the
details how to get archive is explained.</P>
<P>In order to find the information from the page, you must also supply
some other directives to guide searching and constructing
the correct file name:</P>
<P>1) A page regexp directive <CODE>pregexp:ARCHIVE-REGEXP</CODE> matches the A HREF
filename location in the page.</P>
<P>2) Directive <CODE>file:DOWNLOAD-FILE</CODE> tells what is the template to use to
construct the downloadable file (for the <A HREF="#item_new%3A"><CODE>new:</CODE></A> directive).</P>
<P>3) Directive <CODE>vregexp:VERSION-REGEXP</CODE> matches the exact location
in the page from where the version information is extracted. The default
regexp looks for line that says ``The latest version ...is.. 1.4.2''. The
regexp must return submatch 2 for the version number.</P>
<P>To put all together, an example shows more this in action. The following
example should all be PUT ON ONE LINE, while it has been splitted to
separate lines for legibility. The presented configuration line is
explaind in next paragraphs.</P>
<P>Contact absolute <STRONG>page:</STRONG> at <A HREF="http://www.example.com/package.html">http://www.example.com/package.html</A> and
search A HREF urls in the page that match <STRONG>pregexp:</STRONG>. In addition, do
another scan and search the version number in the page from thw
position that match <STRONG>vregexp:</STRONG> (submatch 2). The ?i can makes the search
case insensitive in regexp.</P>
<P>After all the pieces have been found, use template <STRONG>file:</STRONG> to
make the retrievable file using the version number found from
<STRONG>vregexp:</STRONG>. The actual download location is combination of
<STRONG>page:</STRONG> and A HREF <STRONG>pregexp:</STRONG> location. Here is the whole ``one line''
definition in the configuration file:</P>
<PRE>
    <A HREF="http://www.example.com/~foo/package.html">http://www.example.com/~foo/package.html</A>
    page:
    pregexp: package.tar.gz
    vregexp: ((?i)latest.*?version.*?\b([\d][\d.]+).*)
    file: package-1.3.tar.gz
    new:
    x:</PRE>
<P>Still not clear? Let's throw in a complete HTML page where the above would
apply</P>
<PRE>
    &lt;HTML&gt;
    &lt;BODY&gt;</PRE>
<PRE>
    The latest version of package is &lt;B&gt;2.4.1&lt;/B&gt; It can be
    downloaded in several forms:</PRE>
<PRE>
        &lt;A HREF=&quot;download/files/package.tar.gz&quot;&gt;Tar file&lt;/A&gt;
        &lt;A HREF=&quot;download/files/package.zip&quot;&gt;ZIP file</PRE>
<PRE>
    &lt;/BODY&gt;
    &lt;/HTML&gt;</PRE>
<P>For this example it is assumed that package.tar.gz is actually a symbolic
link to the latest standard release file package-2.4.1.tar.gz. From this
page the actual download location would have been
<A HREF="http://www.example.com/~foo/download/files/package-2.4.1.tar.gz">http://www.example.com/~foo/download/files/package-2.4.1.tar.gz</A> So why not
simply download package.tar.gz? Because then the program can't decide if
the version at the page is newer than one stored on disk from the previous
download. With version numbers in the file names, it can.</P>
<P>FURTHER EXAMPLE</P>
<P>It is possible to add <STRONG>rename:</STRONG> directive to change the final name
of the saved file to the above cases. Sometimes people put version number
to ``plain'' files, that are not archives, like</P>
<PRE>
    file.el-1.1
    file.el-1.2</PRE>
<P>the .el files are Emacs editor packages files and it would be very
inconvenient for Emacs users to refer to those with any other name than
plain ``file.el''. To write a complete line to find such files from
a page and save them in plain name, see below. Lines have been broken
again for legibility:</P>
<PRE>
    <A HREF="http://example.com/files/">http://example.com/files/</A>
    page:
    pregexp:\.el-\d
    vregexp:(file.el-([\d.]+))
    <A HREF="file:file.el-1.1">file:file.el-1.1</A>
    new:
    rename:s/-[\d.]+//</PRE>
<P>It effectively says ``See if there is new version of something that
looks like file.el-1.1 and save it under name file.el by deleting the extra
version number at the end of original filename''.</P>
<DT><STRONG><A NAME="item_page%3Afind"><STRONG>page:find</STRONG></A></STRONG><BR>
<DD>
THIS IS NOT FOR FTP directories. Use directive <STRONG>regexp:</STRONG> for FTP.
<P>This is more general instruction than the <STRONG>page:</STRONG> and <STRONG>vregexp:</STRONG>
explained above.</P>
<P>Instruct to download every URL on HTML page matching <STRONG>pregexp:RE</STRONG>. In
typical situation the page maintainer lists his software in the development
page. This example would download every tar.gz file mentined in a page.
Note, that the REGEXP is matched against the A HREF link content, not
the actual text that you see on the page:</P>
<PRE>
    <A HREF="http://www.example.com/index.html">http://www.example.com/index.html</A> page:find pregexp:\.tar.gz$</PRE>
<P>You can also use additional <STRONG>regexp-no:</STRONG> directive if you want to exclude
files after the <STRONG>pregexp:</STRONG> has matched a link.</P>
<PRE>
    <A HREF="http://www.example.com/index.html">http://www.example.com/index.html</A> page:find pregexp:\.tar.gz$ regexp-no:this-packet</PRE>
<P></P>
<DT><STRONG><A NAME="item_pass%3APASSWORD"><STRONG>pass:PASSWORD</STRONG></A></STRONG><BR>
<DD>
For FTP logins. Default value is <CODE>nobody@example.com</CODE>.
<P></P>
<DT><STRONG><A NAME="item_rename%3APERL%2DCODE"><STRONG>rename:PERL-CODE</STRONG></A></STRONG><BR>
<DD>
Rename each file using PERL-CODE. The PERL-CODE must be full perl program
with no spaces anywhere. Following variables are available during the
<CODE>eval()</CODE> of code:
<PRE>
    $ARG = current file name
    $url = complete url for the file</PRE>
<P>For example, if page contains links to .html file that are in fact
text files, this statement would store the filenames as .txt</P>
<PRE>
    <A HREF="http://example.com/dir/">http://example.com/dir/</A> page:find pregexp:\.html rename:s/html/txt/</PRE>
<P></P>
<DT><STRONG><A NAME="item_regexp%3AREGEXP"><STRONG>regexp:REGEXP</STRONG></A></STRONG><BR>
<DD>
Get all files in ftp directory matching regexp. Directive <STRONG>save:</STRONG> is ignored.
<P></P>
<DT><STRONG><A NAME="item_regexp%2Dno%3AREGEXP"><STRONG>regexp-no:REGEXP</STRONG></A></STRONG><BR>
<DD>
After the regexp: directive has matched, explude files that match
directive <STRONG>regexp-no:</STRONG>
<P></P>
<DT><STRONG><A NAME="item_Regexp%3AREGEXP"><STRONG>Regexp:REGEXP</STRONG></A></STRONG><BR>
<DD>
This option is for interactive use. Retrieve all files from HTTP or FTP
site which match REGEXP.
<P></P>
<DT><STRONG><A NAME="item_save%3ALOCAL%2DFILE%2DNAME"><STRONG>save:LOCAL-FILE-NAME</STRONG></A></STRONG><BR>
<DD>
Save file under this name to local disk.
<P></P>
<DT><STRONG><A NAME="item_tagN%3ANAME"><STRONG>tagN:NAME</STRONG></A></STRONG><BR>
<DD>
Downloads can be grouped under <CODE>tagN</CODE> so that e.g. option <STRONG>--Tag1</STRONG> would
start downloading files from that point on until next <CODE>tag1</CODE> is found.
There are currently unlimited number of tag levels: tag1, tag2 and tag3, so
that you can arrange your downlods hierarchially in the configuration file.
For example to download all Linux files rhat you monitor, you would give
option <STRONG>--Tag linux</STRONG>. To download only the NT Emacs latest binary, you
would give option <STRONG>--Tag emacs-nt</STRONG>. Notice that you do not give the
<CODE>level</CODE> in the option, program will find it out from the configuration
file after the tag name matches.
<P>The downloading stops at next tag of the <CODE>same level</CODE>. That is, tag2 stops
only at next tag2, or when upper level tag is found (tag1) or or until end of
file.</P>
<PRE>
    tag1: linux             # All Linux downlods under this category</PRE>
<PRE>
        tag2: sunsite    tag2: another-name-for-this-spot</PRE>
<PRE>
        #   List of files to download from here</PRE>
<PRE>
        tag2: ftp.funet.fi</PRE>
<PRE>
        #   List of files to download from here</PRE>
<PRE>
    tag1: emacs-binary</PRE>
<PRE>
        tag2: emacs-nt</PRE>
<PRE>
        tag2: xemacs-nt</PRE>
<PRE>
        tag2: emacs</PRE>
<PRE>
        tag2: xemacs</PRE>
<P></P>
<DT><STRONG><A NAME="item_x%3A"><STRONG>x:</STRONG></A></STRONG><BR>
<DD>
Extract (unpack) file after download. See also option <STRONG>--unpack</STRONG> and
<STRONG>--no-extract</STRONG> The archive file, say .tar.gz will be extracted the file in
current download location. (see directive <STRONG>lcd:</STRONG>)
<P>The unpack procedure checks the contents of the archive to see if
the package is correctly formed. The de facto archive format is</P>
<PRE>
    package-N.NN.tar.gz</PRE>
<P>In the archive, all files are supposed to be stored under the proper
subdirectory with version information:</P>
<PRE>
    package-N.NN/doc/README
    package-N.NN/doc/INSTALL
    package-N.NN/src/Makefile
    package-N.NN/src/some-code.java</PRE>
<P><CODE>IMPORTANT:</CODE> If the archive does not have a subdirectory for all files, a
subdirectory is created and all items are unpacked under it. The defualt
subdirectory name in constructed from the archive name with currect date
stamp in format:</P>
<PRE>
    package-YYYY.MMDD</PRE>
<P>If the archive name contains something that looks like a version number,
the created directory will be constructed from it, instead of current date.</P>
<PRE>
    package-1.43.tar.gz    =&gt;  package-1.43</PRE>
<P></P>
<DT><STRONG><A NAME="item_xx%3A"><STRONG>xx:</STRONG></A></STRONG><BR>
<DD>
Like directive <STRONG>x:</STRONG> but extract the archive <CODE>as is</CODE>, without
checking content of the archive. If you know that it is ok for the archive
not to include any subdirectories, use this option to suppress creation
of an artificial root package-YYYY.MMDD.
<P></P>
<DT><STRONG><A NAME="item_xopt%3Arm"><STRONG>xopt:rm</STRONG></A></STRONG><BR>
<DD>
This options tells to remove any previous unpack directory.
<P>Sometimes the files in the archive are all read-only and unpacking the
archive second time, after some period of time, would display</P>
<PRE>
    tar: package-3.9.5/.cvsignore: Could not create file: Permission denied
    tar: package-3.9.5/BUGS: Could not create file: Permission denied</PRE>
<P>This is not a serious error, because the archive was already on disk and
tar did not overwrite previous files. It might be good to inform the
archive maintainer, that the files have wrong permissions. It is customary
to expect that distributed kits have writable flag set for all files.</P>
<P></P></DL>
<P>
<HR>
<H1><A NAME="errors">ERRORS</A></H1>
<P>Here is list of possible error messages and how to deal with them.
Turning on  <STRONG>--debug</STRONG> will help to understand how program has
interpreted your configuration file or command line options. Pay close
attention to the generated output, because it may rutn out that the mistake
is in too lose or tight regexp definitions in your side.</P>
<DL>
<DT><STRONG><A NAME="item_ERROR_%7BURL%2DHERE%7D_Bad_file_descriptor"><STRONG>ERROR {URL-HERE} Bad file descriptor</STRONG></A></STRONG><BR>
<DD>
This is ``file not found error''. You have written the filename incorrectly.
Double check the configuration file line.
<P></P></DL>
<P>
<HR>
<H1><A NAME="environment">ENVIRONMENT</A></H1>
<P>Variable <CODE>MYWEBGET_PL_CFG</CODE> can point to the root configuration file in
which you can use <STRONG>include</STRONG> directives to read more configuration files.
The configuration file is read at startup if it exists.</P>
<PRE>
    export MYWEBGET_PL_CFG=$HOME/conf/mywebget.conf</PRE>
<P>
<HR>
<H1><A NAME="see also">SEE ALSO</A></H1>
<P>C program <CODE>wget(1)</CODE> <A HREF="http://www.ccp14.ac.uk/mirror/wget.htm">http://www.ccp14.ac.uk/mirror/wget.htm</A> and
Old Perl 4 program <CODE>webget(1)</CODE> <A HREF="http://www.wg.omron.co.jp/~jfriedl/perl/">http://www.wg.omron.co.jp/~jfriedl/perl/</A>
From the the Libwww Perl library you find scripts
lwp-download(1) lwp-mirror(1) lwp-request(1) lwp-rget(1)</P>
<P>Win32 Cygwin unix utilities at <A HREF="http://www.cygwin.com/">http://www.cygwin.com/</A></P>
<P>
<HR>
<H1><A NAME="availability">AVAILABILITY</A></H1>
<P>Latest version of this file is at CPAN
<A HREF="http://www.perl.com/CPAN-local//scripts/">http://www.perl.com/CPAN-local//scripts/</A> or
<A HREF="http://cpan.perl.org/modules/by-authors/id/J/JA/JARIAALTO/">http://cpan.perl.org/modules/by-authors/id/J/JA/JARIAALTO/</A>
Reach author at <CODE>jari.aalto@poboxes.com</CODE></P>
<P>
<HR>
<H1><A NAME="script categories">SCRIPT CATEGORIES</A></H1>
<P>CPAN/Administrative
CPAN/Web</P>
<P>
<HR>
<H1><A NAME="prerequisites">PREREQUISITES</A></H1>
<P>Modules <CODE>LWP::UserAgent</CODE> and <CODE>use Net::FTP</CODE> are required.</P>
<P>
<HR>
<H1><A NAME="corequisites">COREQUISITES</A></H1>
<P>HTML::Parse
HTML::TextFormat</P>
<P>These modules are dynamically loaded only if directive <STRONG>cnv:text</STRONG>
is used. Otherwise these modules are not loaded.</P>
<P>
<HR>
<H1><A NAME="osnames">OSNAMES</A></H1>
<P><CODE>any</CODE></P>
<P>
<HR>
<H1><A NAME="version">VERSION</A></H1>
<P>$Id: mywebget.html,v 1.1 2005-12-04 20:58:46 hute37 Exp $</P>
<P>
<HR>
<H1><A NAME="author">AUTHOR</A></H1>
<P>Copyright (C) 1996-2001 Jari Aalto. All rights reserved. This program is
free software; you can redistribute it and/or modify it under the same
terms as Perl itself or in terms of Gnu General Public Licence v2 or later.</P>

</BODY>

</HTML>
